{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import emma_util\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"fork\")\n",
    "import pandas as pd\n",
    "import stan\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emma notes (8/22):\n",
    "\n",
    "In general, let's build complexity iteratively. Start by getting reasonable results without worrying about ICAR prior/smoothing. Then use standard ICAR prior (with weight 0.5). Then use full CAR (maybe). Data generation code is reviewed + model without proper CAR prior is reviewed. Another thing it might be nice to implement at some point is using the information about where the annotated images are (i.e., what Census tracts). Could incorporate this as a multinomial (potentially?) \n",
    "\n",
    "Model with simple L2 smoothing (or no smoothing at all - stan_code_with_weighted_ICAR_prior):\n",
    "\n",
    "1. Consistently recovers parameters for realistic parameter settings (with no smoothing)\n",
    "2. Reviewed Stan code and looks good. \n",
    "3. ALso implemented L2 regularization for adjacent Census tracts. This isn't actually the \"proper\" way to do it, but might be useful on real data. Haven't tested how this performs. \n",
    "\n",
    "Model wih full CAR prior (stan_code_proper_car_prior):\n",
    "\n",
    "1. Haven't reviewed this or verified it recovers correct params (recently; I think I did a while ago). When you do review, don't need to re-review all the Bayesian conditioning math; it should be pretty similar to the old code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical_p_y 0.27895894098272467\n",
      "empirical_p_yhat 0.19513207218899767\n",
      "p_y_hat_1_given_y_1 0.656966554350273\n",
      "p_y_hat_1_given_y_0 0.016361806870295523\n",
      "p_y_1_given_y_hat_1 0.9391930921797236\n",
      "p_y_1_given_y_hat_0 0.11889186214731765\n",
      "number of annotated classified negative which were positive: 66/500\n",
      "number of annotated classified positive which were positive: 475/500\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter logit_p_y_1_given_y_hat has 2 priors.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/18000)\n",
      "Sampling:   0% (2/18000)\n",
      "Sampling:   0% (3/18000)\n",
      "Sampling:   0% (4/18000)\n",
      "Sampling:   1% (103/18000)\n",
      "Sampling:   1% (202/18000)\n",
      "Sampling:   2% (301/18000)\n",
      "Sampling:   2% (400/18000)\n",
      "Sampling:   3% (500/18000)\n",
      "Sampling:   3% (600/18000)\n",
      "Sampling:   4% (700/18000)\n",
      "Sampling:   5% (900/18000)\n",
      "Sampling:   6% (1100/18000)\n",
      "Sampling:   7% (1300/18000)\n",
      "Sampling:   8% (1400/18000)\n",
      "Sampling:   9% (1600/18000)\n",
      "Sampling:  10% (1800/18000)\n",
      "Sampling:  11% (2000/18000)\n",
      "Sampling:  12% (2200/18000)\n",
      "Sampling:  13% (2400/18000)\n",
      "Sampling:  14% (2600/18000)\n",
      "Sampling:  16% (2800/18000)\n",
      "Sampling:  17% (3000/18000)\n",
      "Sampling:  17% (3100/18000)\n",
      "Sampling:  18% (3300/18000)\n",
      "Sampling:  19% (3400/18000)\n",
      "Sampling:  19% (3500/18000)\n",
      "Sampling:  21% (3700/18000)\n",
      "Sampling:  22% (3900/18000)\n",
      "Sampling:  22% (4000/18000)\n",
      "Sampling:  23% (4100/18000)\n",
      "Sampling:  24% (4400/18000)\n",
      "Sampling:  26% (4600/18000)\n",
      "Sampling:  27% (4800/18000)\n",
      "Sampling:  28% (5000/18000)\n",
      "Sampling:  29% (5200/18000)\n",
      "Sampling:  30% (5400/18000)\n",
      "Sampling:  31% (5600/18000)\n",
      "Sampling:  32% (5700/18000)\n",
      "Sampling:  33% (5900/18000)\n",
      "Sampling:  34% (6100/18000)\n",
      "Sampling:  35% (6300/18000)\n",
      "Sampling:  36% (6400/18000)\n",
      "Sampling:  37% (6700/18000)\n",
      "Sampling:  39% (7000/18000)\n",
      "Sampling:  40% (7200/18000)\n",
      "Sampling:  41% (7400/18000)\n",
      "Sampling:  42% (7600/18000)\n",
      "Sampling:  43% (7800/18000)\n",
      "Sampling:  44% (8000/18000)\n",
      "Sampling:  45% (8100/18000)\n",
      "Sampling:  46% (8300/18000)\n",
      "Sampling:  47% (8500/18000)\n",
      "Sampling:  48% (8700/18000)\n",
      "Sampling:  49% (8900/18000)\n",
      "Sampling:  51% (9100/18000)\n",
      "Sampling:  52% (9300/18000)\n",
      "Sampling:  53% (9500/18000)\n",
      "Sampling:  53% (9600/18000)\n",
      "Sampling:  54% (9800/18000)\n",
      "Sampling:  56% (10000/18000)"
     ]
    }
   ],
   "source": [
    "icar_prior_setting = 'none'\n",
    "use_simulated_data = True\n",
    "assert icar_prior_setting in ['none', 'cheating', 'proper', 'just_model_p_y']\n",
    "stan_code_with_weighted_ICAR_prior = open('stan_models/weighted_ICAR_prior.stan').read()\n",
    "stan_code_proper_car_prior = open('stan_models/proper_car_prior.stan').read()\n",
    "stan_model_uniform_p_y = open('stan_models/uniform_p_y_prior_just_for_debugging.stan').read()\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    NUM_WARMUP = 3000\n",
    "    NUM_SAMPLES = 1500\n",
    "    if use_simulated_data:\n",
    "        N = 1000\n",
    "        data_to_use = emma_util.generate_simulated_data(N=N, \n",
    "                                                images_per_location=1000, \n",
    "                                                total_annotated_classified_negative=500, \n",
    "                                                total_annotated_classified_positive=500, \n",
    "                                                icar_prior_setting=icar_prior_setting)\n",
    "    else:\n",
    "        data_to_use = emma_util.read_real_data(single_compartment_for_debugging=False)\n",
    "    if icar_prior_setting == 'proper':\n",
    "        raise Exception(\"Haven't verified that this model actually works! Need to review it / check on simulated data. No need to review the parts which are identical to the other model.\")\n",
    "        W = np.zeros((N, N))\n",
    "        \n",
    "        for i in range(len(simulated_data['observed_data']['node1'])):\n",
    "            W[simulated_data['observed_data']['node1'][i] - 1, \n",
    "                                simulated_data['observed_data']['node2'][i] - 1] = 1\n",
    "            W[simulated_data['observed_data']['node2'][i] - 1, \n",
    "                                simulated_data['observed_data']['node1'][i] - 1] = 1\n",
    "        del simulated_data['observed_data']['node1']\n",
    "        del simulated_data['observed_data']['node2']\n",
    "        simulated_data['observed_data']['W'] = W\n",
    "        simulated_data['observed_data']['W_n'] = int(W.sum() / 2)\n",
    "        model = stan.build(stan_code_proper_car_prior, data=simulated_data['observed_data'])\n",
    "    elif icar_prior_setting == 'cheating':\n",
    "        data_to_use['observed_data']['use_ICAR_prior'] = 1\n",
    "        data_to_use['observed_data']['ICAR_prior_weight'] = 0.5\n",
    "        model = stan.build(stan_code_with_weighted_ICAR_prior, data=data_to_use['observed_data'])\n",
    "    elif icar_prior_setting == 'none':\n",
    "        data_to_use['observed_data']['use_ICAR_prior'] = 0\n",
    "        data_to_use['observed_data']['ICAR_prior_weight'] = 0\n",
    "        model = stan.build(stan_code_with_weighted_ICAR_prior, data=data_to_use['observed_data'])\n",
    "    elif icar_prior_setting == 'just_model_p_y':\n",
    "        del data_to_use['observed_data']['node1']\n",
    "        del data_to_use['observed_data']['node2']\n",
    "        del data_to_use['observed_data']['N_edges']\n",
    "        model = stan.build(stan_model_uniform_p_y, data=data_to_use['observed_data'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid icar_prior_options\", icar_prior_setting)\n",
    "    fit = model.sample(num_chains=4, num_warmup=NUM_WARMUP, num_samples=NUM_SAMPLES)\n",
    "    df = fit.to_frame()\n",
    "    if icar_prior_setting == 'just_model_p_y':\n",
    "        print(az.summary(fit, var_names=['p_y_1_given_y_hat_1', 'p_y_1_given_y_hat_0', \n",
    "                                        'p_y_hat_1_given_y_1', 'p_y_hat_1_given_y_0', \n",
    "                                        'empirical_p_yhat', 'p_y']))\n",
    "    else:\n",
    "        print(az.summary(fit, var_names=['p_y_hat_1_given_y_1', 'p_y_hat_1_given_y_0', 'phi_offset', \n",
    "                                    'p_y_1_given_y_hat_1', 'p_y_1_given_y_hat_0', \n",
    "                                    'empirical_p_yhat', 'p_y']))\n",
    "        \n",
    "    if use_simulated_data:\n",
    "        inferred_p_y = [df[f'p_y.{i}'].mean() for i in range(1, N + 1)]\n",
    "        plt.scatter(data_to_use['parameters']['p_Y'], inferred_p_y)\n",
    "        plt.title(\"True vs. inferred p_Y, r = %.2f\" %\n",
    "                pearsonr(data_to_use['parameters']['p_Y'], inferred_p_y)[0])\n",
    "        max_val = max(max(data_to_use['parameters']['p_Y']), max(inferred_p_y))\n",
    "        plt.xlabel(\"True p_Y\")\n",
    "        plt.ylabel(\"Inferred p_Y\")\n",
    "        plt.plot([0, max_val], [0, max_val], 'r--')\n",
    "        plt.xlim([0, max_val])\n",
    "        plt.ylim([0, max_val])\n",
    "        plt.figure(figsize=[12, 3])\n",
    "\n",
    "\n",
    "        if icar_prior_setting == 'proper':\n",
    "            param_names = ['p_y_hat_1_given_y_1', 'p_y_hat_1_given_y_0', \n",
    "            'p_y_1_given_y_hat_1', 'p_y_1_given_y_hat_0', \n",
    "            'phi_offset', 'alpha', 'tau']\n",
    "        elif icar_prior_setting == 'just_model_p_y':\n",
    "            param_names = ['p_y_hat_1_given_y_1', 'p_y_hat_1_given_y_0', \n",
    "            'p_y_1_given_y_hat_1', 'p_y_1_given_y_hat_0', \n",
    "            'phi_offset']\n",
    "        else:\n",
    "            param_names = ['p_y_hat_1_given_y_1', 'p_y_hat_1_given_y_0', \n",
    "            'p_y_1_given_y_hat_1', 'p_y_1_given_y_hat_0']\n",
    "        for k in param_names:\n",
    "            plt.subplot(1, len(param_names), param_names.index(k) + 1)\n",
    "            # histogram of posterior samples\n",
    "            plt.hist(df[k], bins=50, density=True)\n",
    "            plt.title(k)\n",
    "            plt.axvline(data_to_use['parameters'][k], color='red')\n",
    "        plt.show()\n",
    "    else:\n",
    "        empirical_p_yhat = data_to_use['observed_data']['n_classified_positive_by_area'] / data_to_use['observed_data']['n_images_by_area']\n",
    "        print(\"Warning: %i of %i empirical p_yhat values are 0; these are being ignored\" % (sum(np.isnan(empirical_p_yhat)), len(empirical_p_yhat)))\n",
    "        inferred_p_y = np.array([df[f'p_y.{i}'].mean() for i in range(1, len(empirical_p_yhat) + 1)])\n",
    "        inferred_p_y_CIs = [df[f'p_y.{i}'].quantile([0.025, 0.975]) for i in range(1, len(empirical_p_yhat) + 1)]\n",
    "        n_images_by_area = data_to_use['observed_data']['n_images_by_area']\n",
    "        # make errorbar plot\n",
    "        image_cutoff = 100\n",
    "\n",
    "        plt.errorbar(empirical_p_yhat[n_images_by_area >= image_cutoff], inferred_p_y[n_images_by_area >= image_cutoff], \n",
    "                    yerr=np.array(inferred_p_y_CIs)[n_images_by_area >= image_cutoff].T, fmt='o', \n",
    "                    color='blue', \n",
    "                    ecolor='lightgray', elinewidth=1, capsize=3, alpha=0.5, \n",
    "                    label=\"n_images_by_area >= %i\" % image_cutoff)\n",
    "\n",
    "        plt.errorbar(empirical_p_yhat[n_images_by_area < image_cutoff], inferred_p_y[n_images_by_area < image_cutoff], \n",
    "                    yerr=np.array(inferred_p_y_CIs)[n_images_by_area < image_cutoff].T, fmt='o', \n",
    "                    color='red', \n",
    "                    ecolor='lightgray', elinewidth=1, capsize=3, alpha=0.5, \n",
    "                    label=\"n_images_by_area < %i\" % image_cutoff)\n",
    "        plt.legend()\n",
    "\n",
    "        # plot prior on p_y as vertical line. \n",
    "        phi_offset = df['phi_offset'].mean()\n",
    "        plt.axhline(expit(phi_offset), color='black', linestyle='--')\n",
    "        is_nan = np.isnan(empirical_p_yhat)\n",
    "        plt.title(\"Correlation between empirical $p(\\\\hat y = 1)$ and inferred $p(y = 1)$, r = %.2f\" % pearsonr(empirical_p_yhat[~is_nan], inferred_p_y[~is_nan])[0])\n",
    "        plt.xlabel(\"empirical $p(\\\\hat y = 1)$\")\n",
    "        plt.ylabel(\"inferred $p(y = 1)$\")\n",
    "        # logarithmic axes\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_stan_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
