{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shortuuid\n",
    "from glob import glob \n",
    "import pandas as pd \n",
    "\n",
    "from cambrian.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from cambrian.conversation import conv_templates, SeparatorStyle\n",
    "from cambrian.model.builder import load_pretrained_model\n",
    "from cambrian.utils import disable_torch_init\n",
    "from cambrian.mm_utils import tokenizer_image_token, process_images, get_model_name_from_path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:06:47 \u001b[32mbuilder.py:119 [I]\u001b[0m → Loading Cambrian from nyu-visionx/cambrian-13b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:06:49 \u001b[32mbuilder.py:105 [I]\u001b[0m → Loading **SigLIP CLIP** Vision Tower: siglip/CLIP-ViT-SO400M-14-384-interp576\n",
      "00:06:49 \u001b[33mbase_encoder.py:44 [W]\u001b[0m → Unfreezing MM Vision Tower: False\n",
      "00:06:49 \u001b[32mbuilder.py:99 [I]\u001b[0m → Loading **OpenAI CLIP** Vision Tower: openai/clip-vit-large-patch14-336-interp576\n",
      "00:06:49 \u001b[33mbase_encoder.py:44 [W]\u001b[0m → Unfreezing MM Vision Tower: False\n",
      "00:06:49 \u001b[32mbuilder.py:116 [I]\u001b[0m → Loading **DINO Vision Tower: facebook/dinov2-giant-res378-interp576\n",
      "00:06:49 \u001b[33mbase_encoder.py:44 [W]\u001b[0m → Unfreezing MM Vision Tower: False\n",
      "00:06:49 \u001b[32mbuilder.py:111 [I]\u001b[0m → Loading **ConvNeXt CLIP** Vision Tower: clip-convnext-XXL-multi-stage-interp9216\n",
      "00:06:49 \u001b[33mbase_encoder.py:44 [W]\u001b[0m → Unfreezing MM Vision Tower: False\n",
      "00:06:52 \u001b[32mmodeling.py:799 [I]\u001b[0m → We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 11/11 [02:43<00:00, 14.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:09:36 \u001b[32mfactory.py:212 [I]\u001b[0m → Loaded hf-hub:timm/ViT-SO400M-14-SigLIP-384 model config.\n",
      "00:09:50 \u001b[32mfactory.py:299 [I]\u001b[0m → Loading pretrained hf-hub:timm/ViT-SO400M-14-SigLIP-384 weights (/home/mwf62/.cache/huggingface/hub/models--timm--ViT-SO400M-14-SigLIP-384/snapshots/ac16108d567c4389e6cd2b11c9b8585f7474435b/open_clip_pytorch_model.bin).\n",
      "00:09:55 \u001b[32mmodeling.py:799 [I]\u001b[0m → We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "00:10:20 \u001b[33mdino_encoder.py:89 [W]\u001b[0m → Overriding DinoVisionTower image size of 518 with 378\n",
      "00:10:20 \u001b[32mdino_encoder.py:98 [I]\u001b[0m → Dino Vision Processor: BitImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 378,\n",
      "    \"width\": 378\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"BitImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 378\n",
      "  }\n",
      "}\n",
      "\n",
      "00:10:23 \u001b[32mfactory.py:212 [I]\u001b[0m → Loaded hf-hub:laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup model config.\n",
      "00:10:39 \u001b[32mfactory.py:299 [I]\u001b[0m → Loading pretrained hf-hub:laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup weights (/home/mwf62/.cache/huggingface/hub/models--laion--CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup/snapshots/9f3e8ee3f383c672388d9178afe70af9e63ac9df/open_clip_pytorch_model.bin).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cambrian-phi3-3b\n",
    "# conv_mode = \"phi3\"\n",
    "\n",
    "# cambrian-8b\n",
    "#conv_mode = \"llama_3\" \n",
    "\n",
    "# cambrian-34b\n",
    "#conv_mode = \"chatml_direct\"\n",
    "\n",
    "# cambrian-13b\n",
    "conv_mode = \"vicuna_v1\"\n",
    "\n",
    "def process(image, question, tokenizer, image_processor, model_config):\n",
    "    qs = question\n",
    "\n",
    "    if model_config.mm_use_im_start_end:\n",
    "        qs = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + qs\n",
    "    else:\n",
    "        qs = DEFAULT_IMAGE_TOKEN + '\\n' + qs\n",
    "\n",
    "    conv = conv_templates[conv_mode].copy()\n",
    "    conv.append_message(conv.roles[0], qs)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "    \n",
    "    image_size = [image.size]\n",
    "    image_tensor = process_images([image], image_processor, model_config)\n",
    "\n",
    "    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
    "\n",
    "    return input_ids, image_tensor, image_size, prompt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "model_path = os.path.expanduser(\"nyu-visionx/cambrian-13b\")\n",
    "model_name = get_model_name_from_path(model_path)\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, None, model_name)\n",
    "\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5246\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>split</th>\n",
       "      <th>class</th>\n",
       "      <th>q0</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>train</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>train</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>train</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>train</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>train</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>test</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5242</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>test</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>test</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>test</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>../../datasets/anl_set_jun16_w_extra_from_orig...</td>\n",
       "      <td>test</td>\n",
       "      <td>drivable</td>\n",
       "      <td>Can you safely drive through the water in this...</td>\n",
       "      <td>Does this image show more than a foot of stand...</td>\n",
       "      <td>Is the street in this image flooded?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5246 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  split     class  \\\n",
       "0     ../../datasets/anl_set_jun16_w_extra_from_orig...  train  drivable   \n",
       "1     ../../datasets/anl_set_jun16_w_extra_from_orig...  train  drivable   \n",
       "2     ../../datasets/anl_set_jun16_w_extra_from_orig...  train  drivable   \n",
       "3     ../../datasets/anl_set_jun16_w_extra_from_orig...  train  drivable   \n",
       "4     ../../datasets/anl_set_jun16_w_extra_from_orig...  train  drivable   \n",
       "...                                                 ...    ...       ...   \n",
       "5241  ../../datasets/anl_set_jun16_w_extra_from_orig...   test  drivable   \n",
       "5242  ../../datasets/anl_set_jun16_w_extra_from_orig...   test  drivable   \n",
       "5243  ../../datasets/anl_set_jun16_w_extra_from_orig...   test  drivable   \n",
       "5244  ../../datasets/anl_set_jun16_w_extra_from_orig...   test  drivable   \n",
       "5245  ../../datasets/anl_set_jun16_w_extra_from_orig...   test  drivable   \n",
       "\n",
       "                                                     q0  \\\n",
       "0     Can you safely drive through the water in this...   \n",
       "1     Can you safely drive through the water in this...   \n",
       "2     Can you safely drive through the water in this...   \n",
       "3     Can you safely drive through the water in this...   \n",
       "4     Can you safely drive through the water in this...   \n",
       "...                                                 ...   \n",
       "5241  Can you safely drive through the water in this...   \n",
       "5242  Can you safely drive through the water in this...   \n",
       "5243  Can you safely drive through the water in this...   \n",
       "5244  Can you safely drive through the water in this...   \n",
       "5245  Can you safely drive through the water in this...   \n",
       "\n",
       "                                                     q1  \\\n",
       "0     Does this image show more than a foot of stand...   \n",
       "1     Does this image show more than a foot of stand...   \n",
       "2     Does this image show more than a foot of stand...   \n",
       "3     Does this image show more than a foot of stand...   \n",
       "4     Does this image show more than a foot of stand...   \n",
       "...                                                 ...   \n",
       "5241  Does this image show more than a foot of stand...   \n",
       "5242  Does this image show more than a foot of stand...   \n",
       "5243  Does this image show more than a foot of stand...   \n",
       "5244  Does this image show more than a foot of stand...   \n",
       "5245  Does this image show more than a foot of stand...   \n",
       "\n",
       "                                        q2  \n",
       "0     Is the street in this image flooded?  \n",
       "1     Is the street in this image flooded?  \n",
       "2     Is the street in this image flooded?  \n",
       "3     Is the street in this image flooded?  \n",
       "4     Is the street in this image flooded?  \n",
       "...                                    ...  \n",
       "5241  Is the street in this image flooded?  \n",
       "5242  Is the street in this image flooded?  \n",
       "5243  Is the street in this image flooded?  \n",
       "5244  Is the street in this image flooded?  \n",
       "5245  Is the street in this image flooded?  \n",
       "\n",
       "[5246 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anl_set_jun16_w_extra_from_original = glob(\"../../datasets/anl_set_jun16_w_extra_from_original/*/*/*.jpg\")\n",
    "print(len(anl_set_jun16_w_extra_from_original))\n",
    "# turn into dataframe \n",
    "anl_set_jun16_w_extra_from_original_df = pd.DataFrame(anl_set_jun16_w_extra_from_original, columns=[\"image_path\"])\n",
    "\n",
    "anl_set_jun16_w_extra_from_original_df[\"split\"] = anl_set_jun16_w_extra_from_original_df[\"image_path\"].apply(lambda x: x.split(\"/\")[-3])\n",
    "anl_set_jun16_w_extra_from_original_df[\"class\"] = anl_set_jun16_w_extra_from_original_df[\"image_path\"].apply(lambda x: x.split(\"/\")[-2])\n",
    "\n",
    "anl_set_jun16_w_extra_from_original_df[\"q0\"] = \"Does this image show a flooded street?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q1\"] = \"Does this image show more than a foot of standing water?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q2\"] = \"Is the street in this image flooded?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q3\"] = \"Could a car drive through the water in this image?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q4\"] = \"Does this image show a visible street?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q5\"] = \"Is there any visible street in this image?\"\n",
    "anl_set_jun16_w_extra_from_original_df[\"q6\"] = \"Is the view from windshield in this image too obstructed?\"\n",
    "\n",
    "\n",
    "anl_set_jun16_w_extra_from_original_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/utils.py:1290: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "1it [00:24, 24.09s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "2it [00:30, 13.88s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "3it [00:37, 10.81s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "4it [00:46,  9.91s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "5it [00:53,  8.88s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "6it [01:00,  8.19s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "7it [01:06,  7.53s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "8it [01:13,  7.38s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "9it [01:20,  7.29s/it]/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "9it [01:21,  9.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m---> 14\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(output_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     26\u001b[0m anl_set_jun16_w_extra_from_original_df\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m outputs\n",
      "File \u001b[0;32m/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/ju/matt/street-flooding/cambrian/cambrian/model/language_model/cambrian_llama.py:478\u001b[0m, in \u001b[0;36mCambrianLlamaForCausalLM.generate\u001b[0;34m(self, inputs, images, image_sizes, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model()\u001b[38;5;241m.\u001b[39membed_tokens(inputs)\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/utils.py:1474\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1458\u001b[0m         input_ids,\n\u001b[1;32m   1459\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/share/ju/conda_virtualenvs/cambrian/lib/python3.10/site-packages/transformers/generation/utils.py:2392\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m     unfinished_sequences \u001b[38;5;241m=\u001b[39m unfinished_sequences\u001b[38;5;241m.\u001b[39mmul(\n\u001b[1;32m   2388\u001b[0m         next_tokens\u001b[38;5;241m.\u001b[39mtile(eos_token_id_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mne(eos_token_id_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mprod(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2389\u001b[0m     )\n\u001b[1;32m   2391\u001b[0m     \u001b[38;5;66;03m# stop when each sentence is finished\u001b[39;00m\n\u001b[0;32m-> 2392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unfinished_sequences\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2393\u001b[0m         this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# stop if we exceed the maximum length\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(anl_set_jun16_w_extra_from_original_df.iterrows()):\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        image_path = row[\"image_path\"]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        question = row[\"q\" + str(i)]\n",
    "\n",
    "        input_ids, image_tensor, image_sizes, prompt = process(image, question, tokenizer, image_processor, model.config)\n",
    "        input_ids = input_ids.to(device='cuda', non_blocking=True)\n",
    "        with torch.inference_mode():\n",
    "            output_ids = model.generate(\n",
    "                input_ids,\n",
    "                images=image_tensor,\n",
    "                image_sizes=image_sizes,\n",
    "                do_sample=True if temperature > 0 else False,\n",
    "                temperature=temperature,\n",
    "                num_beams=1,\n",
    "                max_new_tokens=512,\n",
    "                use_cache=True)\n",
    "\n",
    "        outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "        anl_set_jun16_w_extra_from_original_df.loc[index, \"response_\" + str(i)] = outputs\n",
    "\n",
    "        # write to csv in case of crash\n",
    "        anl_set_jun16_w_extra_from_original_df.to_csv(\"anl_set_jun16_w_extra_from_original_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
